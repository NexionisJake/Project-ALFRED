# ğŸ¤– PROJECT JHANGYA - Advanced AI Assistant

A fully integrated, multi-modal AI assistant with voice control, vision capabilities, and sentiment-aware visual feedback.

## ğŸŒŸ Features

### Core Systems
- **ğŸ§  Hybrid Brain**: Groq Cloud (Llama 3.3 70B) + Ollama Local (Hermes 3)
- **ğŸ‘‚ Ears**: OpenWakeWord + Faster-Whisper voice recognition
- **ğŸ‘ï¸ Eyes**: Llama 4 Scout 17B vision model for screen analysis
- **ğŸ’¬ Voice**: Edge TTS for natural speech output
- **ğŸ¨ Face**: PyQt6 Arc Reactor GUI with sentiment-aware colors

### ğŸ› ï¸ Capabilities (8 Tools)

1. **Application Launcher** - Open apps like Chrome, Spotify, VS Code
2. **System Monitor** - Check CPU and RAM usage
3. **Web Search** - Instant Google searches
4. **Volume Control** - Adjust or mute system volume
5. **Media Controls** - Play/pause, next/previous track (works with Spotify, YouTube, etc.)
6. **Personal Knowledge Base** - Query your custom brain.txt file

### ğŸ­ Sentiment Engine

The Arc Reactor changes color based on context:
- **ğŸ”µ Cyan (Blue)** - Neutral/Default state
- **ğŸŸ¢ Green** - Success/Positive responses
- **ğŸŸ  Orange** - Warnings/Alerts
- **ğŸ”´ Red** - Errors/Problems

### ğŸ’¾ Long-Term Memory

- Conversations persist across sessions via `long_term_memory.json`
- Automatic summarization every 10 messages
- Loads previous context on startup

## ğŸ“‹ Requirements

```bash
# Install dependencies
pip install -r requirements.txt
```

### Required API Keys

Create a `.env` file:
```
GROQ_API_KEY=your_groq_api_key_here
```

### Local Models (Ollama)

Install Ollama and pull required models:
```bash
ollama pull hermes3
ollama pull llama3.2-vision
```

## ğŸš€ Quick Start

1. **Pre-Flight Check**
```bash
python preflight_check.py
```

2. **Launch System**
```bash
python main.py
```

3. **Wake Word Activation**
   - Say "Jarvis" to activate
   - Speak your command
   - Say "thank you" or "goodbye" to end conversation

## ğŸ“ Personal Knowledge Base

Edit `brain.txt` to add your personal information:
```
My name is [Your Name].
My WiFi password is [Password].
My favorite [thing] is [value].
```

The AI can then recall this information when asked!

## ğŸ§ª Testing

### Test Sentiment Colors
```bash
python test_sentiment.py
```

### Test Individual Components
```bash
python overlay.py  # Test GUI overlay
python ears.py     # Test voice input
python eyes.py     # Test vision capture
```

## ğŸ“‚ Project Structure

```
Project JHANGYA/
â”œâ”€â”€ main.py              # Main orchestrator
â”œâ”€â”€ tools.py             # 8 AI tools
â”œâ”€â”€ overlay.py           # GUI with sentiment engine
â”œâ”€â”€ ears.py              # Voice input (Whisper)
â”œâ”€â”€ eyes.py              # Vision capture
â”œâ”€â”€ config.py            # Configuration
â”œâ”€â”€ brain.txt            # Personal knowledge base
â”œâ”€â”€ .env                 # API keys
â”œâ”€â”€ long_term_memory.json  # Conversation history
â””â”€â”€ requirements.txt     # Dependencies
```

## ğŸ® Example Commands

**Application Control:**
- "Jarvis, open Spotify"
- "Launch calculator"
- "Start Chrome"

**System Commands:**
- "Check system status"
- "Volume up"
- "Mute the system"

**Media Control:**
- "Pause the music"
- "Skip this song"
- "Go back to the previous track"

**Personal Knowledge:**
- "What's my WiFi password?"
- "What's my favorite music genre?"
- "Tell me about my project"

**Vision:**
- "Look at my screen and describe what you see"
- "What's in this image?"
- "Read the text on my screen"

**Conversation:**
- "Tell me a joke"
- "What's 2+2?"
- "Explain quantum physics"

## ğŸ¨ Sentiment Examples

- **Green Response**: "Jarvis, play music" â†’ "âœ“ Successfully launched Spotify" (GREEN)
- **Orange Warning**: "Should I delete system32?" â†’ "âš ï¸ That's dangerous!" (ORANGE)
- **Red Error**: "Open nonexistent_app" â†’ "âŒ Failed to launch" (RED)

## ğŸ”§ Configuration

Edit `config.py` to customize:
- Models (cloud/local/vision)
- Wake word
- Memory depth
- Voice settings
- System keywords

## ğŸ› Troubleshooting

**Issue**: Microphone not working
- Check `ears.py` isn't running separately
- Verify microphone permissions

**Issue**: GUI not showing
- Ensure PyQt6 is installed
- Run `python test_sentiment.py` to test overlay

**Issue**: Tools not working
- Run `python preflight_check.py`
- Verify all imports are successful

**Issue**: API errors
- Check `.env` file has valid GROQ_API_KEY
- Verify Ollama is running: `ollama list`

## ğŸ“Š System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          USER INTERACTION               â”‚
â”‚  (Voice Input via Microphone)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          EARS (Whisper STT)             â”‚
â”‚  - Wake word detection                  â”‚
â”‚  - Speech-to-text transcription         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     BRAIN (Hybrid Intelligence)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Cloud Brain (Groq Llama 3.3)  â”‚   â”‚
â”‚  â”‚  - Conversation                  â”‚   â”‚
â”‚  â”‚  - Sentiment analysis            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Local Body (Ollama Hermes 3)   â”‚   â”‚
â”‚  â”‚  - Tool execution                â”‚   â”‚
â”‚  â”‚  - System commands               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Eyes (Llama Scout Vision)      â”‚   â”‚
â”‚  â”‚  - Screen analysis               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    TOOLS     â”‚  â”‚  MEMORY SYSTEM  â”‚
â”‚  8 Actions   â”‚  â”‚  - Short-term   â”‚
â”‚              â”‚  â”‚  - Long-term    â”‚
â”‚              â”‚  â”‚  - Knowledge    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         OUTPUT SYSTEMS                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Voice (TTS)   â”‚  â”‚  GUI Overlay â”‚  â”‚
â”‚  â”‚  Edge TTS      â”‚  â”‚  Arc Reactor â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Technical Details

### Sentiment Engine Logic
1. System prompt instructs AI to prefix responses with tags
2. Regex extracts `[HAPPY]`, `[ALERT]`, `[ERROR]`, `[NEUTRAL]`
3. Tags mapped to colors: Green, Orange, Red, Cyan
4. Color signals sent to Qt GUI
5. Smooth interpolation for visual transitions

### Memory Persistence
1. Every response serialized to JSON
2. Message objects converted to dicts
3. Saved to `long_term_memory.json`
4. Loaded on startup and deserialized

### Knowledge Retrieval (RAG Lite)
1. User query â†’ `search_knowledge_base` tool
2. Opens `brain.txt` file
3. Simple keyword matching
4. Returns matching lines
5. Separates private data from cloud AI

## ğŸ† Credits

- **LangChain** - AI framework
- **Groq** - Cloud inference
- **Ollama** - Local models
- **Faster-Whisper** - Speech recognition
- **Edge TTS** - Voice synthesis
- **PyQt6** - GUI framework

## ğŸ“œ License

MIT License - Feel free to modify and extend!

---

**ğŸš€ SYSTEM STATUS: ALL SYSTEMS ONLINE**

Welcome to the future of personal AI assistants.
